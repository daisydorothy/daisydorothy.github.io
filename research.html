<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2EEQKHS8DE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2EEQKHS8DE');
</script>
  <title>Daisy Leigh</title>

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Daisy Leigh is a recent Stanford Lingusitics PhD graduate">
  <meta name="author" content="Daisy Leigh">
  <meta name="keywords" content="linguistics, cognitive science, cogsci, linguist, language, psycholinguistics, social, socio, pragmatics, stanford">
  <meta http-equiv="content-language" content="en">

  <!-- Bootstrap CSS -->

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

</head>

<body>
  <!-- TODO: add picture -->

  <div class="container">
    <div class="text-center">
    </br>
    <hr style="border: 1px dashed black;" />
    <h1 style="font-size:32pt"> research </h1>
    <!-- TODO: make the email grey
    ddleigh@stanford.edu -->
  </br>

  <!-- TODO: make CV non pdf just a page -->
  <ul class="nav justify-content-center">
    <li class="nav-item">
      <a class="nav-link" href="http://daisydorothy.github.io/">home</a>
    </li>
    <li class="nav-item">
      <a class="nav-link" href="http://daisydorothy.github.io/fun_stuff.html">fun stuff</a>
    </li>
    <!-- <li class="nav-item">
      <a class="nav-link active" href="https://web.stanford.edu/~ddleigh/Daisy_LeighCV_september2019.pdf">cv</a>
    </li> -->
  </ul>
  <hr style="border: 1px dashed black;" />
</div>
</div>


<div class="container">
  <p>
    <div class="media">
      <!--<a class="mr-3" href="https://web.stanford.edu/~ddleigh/FOO">
      <!--  <img src="style_in_time_test.jpeg" alt="Generic placeholder image">
      </a> -->
      <div class="media-body">
        <h5 class="mt-0"> Style in Time: Online perception of sociolinguistic cues </h5>
        My dissertation examined how socioindexical cues like high-rising terminals (also known as 'uptalk') shape listeners' real-time perceptions of speakers.
        Using a series of eye-tracking experiments, I investigated how different cues individually and jointly contribute to participants' judgments about speakers' social identities.
        <br>
        <br>
        <p>
      <a class="btn btn-outline-primary btn-sm" data-toggle="collapse" href="#collapsAbstract" role="button" aria-expanded="false" aria-controls="collapsAbstract">
        read the abstract
      </a>   <a class="btn btn-outline-primary btn-sm" href="https://daisydorothy.github.io/talkin_like_a_valley_girl_CUNY2021.pdf" role="button"> click for slides [CUNY 2021]</a>   <a class="btn btn-outline-primary btn-sm" href="https://daisydorothy.github.io/style_in_time_DEFENCE2021.pdf" role="button"> click for slides [Dissertation Defense]</a> <a class="btn btn-outline-primary btn-sm" href="mailto:daisydorothyleigh@gmail.com" role="button"> email for the diss!</a>
    </p>
    <div class="collapse" id="collapsAbstract">
      <div class="card card-body">
        Speakers use styles - combinations of socially meaningful sounds - to construct and
project different social identities, or personae. How do listeners recognize these sounds
as belonging to a particular linguistic style, spoken by a particular kind of person?
Sociolinguistic work has shown that the contribution of individual speech features
(or cues) is highly mutable, and context-dependent - suggesting that listeners must
integrate the meaning contributions of individual cues with all the other social impressions
that arise when hearing someone talk. In this dissertation, I ask how and
when they do so. I present results from a series of web-based experiments that ask
how two cues -  -in' (vs. -ing) and HRT ('uptalk') - modulate listeners' implicit,
online inferences, and explicit, offline judgments about two social personae; a Tough
and a Valley Girl speaker.
<br>
<br>
I first show that the contribution of these cues on explicit, offline judgments is dependent
on the contextual information available to listeners: sociolinguistic cues don't
vary just in the range of meanings they elicit, but also in the degree to which they give
rise to specific meanings. I then show that listeners rapidly reconcile the meaning
contributions of sociolinguistic cues when making inferences about a speaker's persona,
and that the extent to which listeners' online and offline beliefs are modulated
by a given cue is broadly proportional to the cue's socioindexical informativity. I
then ask whether these results generalize to an additional set of four voices: I show
that they do, and that listeners weigh the meaning contributions of a cue against
their existing expectations about the speaker. Finally, I show that when faced with
conflicting information about a speaker's persona, listeners will variably weight the
contribution of a given cue based on voice-specific detail. Together, these results
point to a probabilistic account of sociolinguistic perception in which listeners integrate
various sources of contextual and linguistic information, but prioritize and place
the greatest weight on the most informative aspects.
<br>
<br>
This dissertation draws on insights from the cognitive sciences in systematically
investigating problems and phenomena that are central to the study of sociolinguistic
style. In doing so, it provides a methodological and conceptual framework for future
experimentation and theorization.

      </div>
    </div>
      </div>
    </div>

    </br>
    <div class="media">
      <!--<a class="mr-3" href="https://web.stanford.edu/~ddleigh/FOO">
      <!--  <img src="style_in_time_test.jpeg" alt="Generic placeholder image">
      </a> -->
      <div class="media-body">
        <h5 class="mt-0"> Expectations of speaker performance and social meanings in Tweets </h5>
        Sociolinguistic work has found that listeners make social evaluations about speakers based on the linguistic features they use. I wanted to understand whether previously-established sociolinguistic effects would replicate when people didn't hear a speaker - but read a Tweet including the feature instead.
        <br>
        I ran a series of experiments, and found that they did - but that also, the highly performative modality of Twitter might have been shaping 'listener' expectations of 'speakerâ€™ performance - thereby generating distinct sets of social evaluations for particular variants: the realizations of (ING), and the use of <i> um </i> and <i> uh</i>.
         <br>
         <br>
         <!-- <a href="https://web.stanford.edu/~ddleigh/expecting_a_performance_NWAV2018_slides.pdf">[slides from NWAV 2018]</a> -->
          <a class="btn btn-outline-primary btn-sm" href="https://daisydorothy.github.io/expecting_a_performance_NWAV2018_slides.pdf" role="button"> click for slides [NWAV 2018]</a>
      </div>
    </div>

    </br>
    <div class="media">
      <!--<a class="mr-3" href="https://web.stanford.edu/~ddleigh/FOO">
      <!--  <img src="style_in_time_test.jpeg" alt="Generic placeholder image">
      </a> -->
      <div class="media-body">
        <h5 class="mt-0"> Effects of phonetic distance and social evaluation on vowel convergence </h5>
         I ran web-based experiments where people recorded themselves repeating other speakers' sentences - to try and understand vocalic convergence behavior (i.e., why people might start talking a bit more like someone they've just heard).
         <br>
         <br>
         <!-- <a href="https://web.stanford.edu/~ddleigh/phonetic_adaptation_VALP2019.pdf">[slides from VALP 2019]</a>, email for mansuscript. -->
         <a class="btn btn-outline-primary btn-sm" href="https://daisydorothy.github.io/phonetic_adaptation_VALP2019.pdf" role="button"> click for slides [VALP 2018]</a> <a class="btn btn-outline-primary btn-sm" href="mailto:daisydorothyleigh@gmail.com" role="button"> email for manuscript </a>
      </div>
    </div>
    </br>
    <div class="media">
      <!--<a class="mr-3" href="https://web.stanford.edu/~ddleigh/FOO">
      <!--  <img src="style_in_time_test.jpeg" alt="Generic placeholder image">
      </a> -->
      <div class="media-body">
        <h5 class="mt-0"> The frequency and distribution of <i> um </i> and <i> uh </i> in acquistion </h5>
        In this corpus study, I investigated how young children's production of the delay markers <i> um </i> and <i> uh </i> changes over time, to meet changing conversational needs as their linguistic skills develop .
        <small class="text-muted">
        <br>
        BTW: For this project, I annotated a large portion of the <a href="http://childes.talkbank.org/access/Eng-NA/Providence.html">Providence Corpus</a> for turn-type. <a href="mailto:daisydorothyleigh@gmail.com"> Email me</a> if you want the data.
      </small>
        <br>
        <br>
        <a class="btn btn-outline-primary btn-sm" href="https://daisydorothy.github.io/frequency_and_distribution_of_DMs_IASCL2017.pdf" role="button"> click for poster [IASCL 2017]</a> <a class="btn btn-outline-primary btn-sm" href="mailto:daisydorothyleigh@gmail.com" role="button"> email for manuscript </a>
        <!-- <a href="https://web.stanford.edu/~ddleigh/frequency_and_distribution_of_DMs_IASCL2017.pdf">[poster from IASCL 2017]</a>, email for manuscript. -->
      </div>
    </div>
  </p>

</div>

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>
</body>
</html>
